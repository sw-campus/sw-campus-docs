# Grafana 대시보드 가이드

sw-campus 모니터링을 위한 Grafana 대시보드 사용 가이드입니다.

---

## 모니터링 기본 개념

> 운영 환경에서 "지금 서비스가 잘 돌아가고 있나?"를 확인하려면 3가지를 봐야 합니다.

### 관측 가능성(Observability)의 3요소

```
┌────────────────────────────────────────────────────────────────────┐
│                        우리 서비스                                    │
│  ┌─────────┐    ┌─────────┐    ┌─────────┐    ┌─────────┐          │
│  │ API     │───▶│ Service │───▶│   DB    │───▶│ 외부API  │          │
│  │ Gateway │    │  Layer  │    │         │    │         │          │
│  └─────────┘    └─────────┘    └─────────┘    └─────────┘          │
│       │              │              │              │               │
│       ▼              ▼              ▼              ▼               │
│  ┌──────────────────────────────────────────────────────────────┐  │
│  │                     3가지 데이터 수집                            │  │
│  │  📊 Metrics    📝 Logs    🔗 Traces                           │  │
│  └──────────────────────────────────────────────────────────────┘  │
└────────────────────────────────────────────────────────────────────┘
```

### 1. 메트릭 (Metrics) 📊

**"숫자로 보는 서비스 상태"**

```
- CPU 사용률: 45%
- 메모리 사용량: 1.2GB
- 초당 요청 수: 150 req/s
- 에러율: 0.5%
- 응답시간: 120ms
```

- **언제 보나요?** 서비스가 전반적으로 건강한지 빠르게 파악할 때
- **개발로 치면:** `System.out.println("처리 시간: " + time + "ms")` 를 자동으로 수집하는 것

### 2. 로그 (Logs) 📝

**"서비스가 남긴 일기장"**

```
2024-01-21 10:23:45 INFO  [UserService] 사용자 로그인 성공: userId=123
2024-01-21 10:23:46 ERROR [PaymentService] 결제 실패: NullPointerException
2024-01-21 10:23:47 WARN  [DBConnection] 연결 풀 부족, 대기 중...
```

- **언제 보나요?** "왜 에러가 났지?" 원인을 파악할 때
- **개발로 치면:** `log.info()`, `log.error()` 로 남긴 내용

### 3. 트레이스 (Traces) 🔗

**"하나의 요청이 어디를 거쳐갔는지 추적"**

```
사용자가 "주문하기" 버튼 클릭 시

[TraceID: abc-123]
├─ API Gateway (2ms)
│   └─ OrderService.createOrder (150ms)
│       ├─ UserService.getUser (20ms)
│       ├─ ProductService.checkStock (30ms)  ⚠️ 느림!
│       └─ PaymentService.process (95ms)
│           └─ 외부 PG API 호출 (90ms)  ❌ 여기가 병목!
```

- **언제 보나요?** "어디서 느려진 거지?", "어느 서비스에서 에러 난 거지?"
- **개발로 치면:** 디버거로 콜스택 따라가는 것과 비슷

---

## 우리가 사용하는 도구들

```
┌─────────────────────────────────────────────────────────────────┐
│                         Grafana                                 │
│             "메트릭, 로그, 트레이스를 예쁘게 보여주는 도구"                │
└─────────────────────────────────────────────────────────────────┘
          │                 │                 │
          ▼                 ▼                 ▼
┌─────────────────┐ ┌───────────┐ ┌─────────────────────┐
│   Prometheus    │ │   Loki    │ │       Tempo         │
│   (메트릭 DB)     │ │ (로그 DB)  │ │    (트레이스 DB)      │
└─────────────────┘ └───────────┘ └─────────────────────┘
          ▲                 ▲                 ▲
          └─────────────────┼─────────────────┘
                            │
              ┌─────────────────────────┐
              │   sw-campus-server      │
              │                         │
              │  Micrometer  → 메트릭     │
              │  Logback     → 로그      │
              │  OTel Agent  → 트레이스   │
              └─────────────────────────┘
```

| 도구 | 역할 | 한마디로 |
|------|------|----------|
| **Grafana** | 시각화 대시보드 | 모니터링계의 엑셀 |
| **Prometheus** | 메트릭 저장소 | 숫자 전문 DB (like Redis) |
| **Loki** | 로그 저장소 | 로그 전문 DB (like Elasticsearch) |
| **Tempo** | 트레이스 저장소 | 요청 추적 전문 DB |

---

## 대시보드 목록

| 대시보드 | 언제 보나요? | 경로 |
|----------|-------------|------|
| **서비스 APM 개요** | 서비스 전체 상태 빠르게 파악 | `/d/service-apm-overview` |
| **애플리케이션 로그** | 에러 메시지 확인, 원인 분석 | `/d/app-logs-enhanced` |
| **분산 추적** | 요청 흐름 추적, 병목 구간 찾기 | `/d/distributed-tracing` |
| **애플리케이션 인프라** | CPU/메모리 등 리소스 확인 | `/d/app-infrastructure` |

---

## 알람과 대응

### 알람 목록

| 알람 | 의미 | 뭘 봐야 하나요? |
|------|------|----------------|
| `PodCrashLoopBackOff` | Pod가 계속 죽고 재시작 | 로그 → 에러 메시지 확인 |
| `PodRestarting` | 15분에 3번 이상 재시작 | 인프라 → 로그 |
| `HighErrorLogRate` | 에러 로그 급증 | 로그 → 트레이스 |
| `HighHeapMemoryUsage` | JVM 메모리 85% 이상 | 인프라 → 로그 (OOM 확인) |
| `HighContainerCPU` | CPU 과다 사용 | 인프라 → APM |
| `HighContainerMemory` | 메모리 과다 사용 | 인프라 → 로그 |

### 알람 왔을 때 행동 순서

```
1. 알람 확인
   "어떤 알람이지? Pod 문제? 에러? 리소스?"
        ↓
2. 서비스 APM 개요
   "지금 에러율이나 지연시간이 튀었나?"
        ↓
3. 애플리케이션 로그
   "무슨 에러가 났지? traceId 있나?"
        ↓
4. 분산 추적 (필요시)
   "어느 구간에서 문제가 생긴 거지?"
        ↓
5. 애플리케이션 인프라 (필요시)
   "리소스(CPU/메모리) 부족한 건 아니지?"
```

---

## 자주 있는 상황별 대응

### "서비스가 느려요"

```
APM 개요 → 지연시간 그래프 확인
    ↓
분산 추적 → 느린 요청 클릭 → 어느 구간이 오래 걸리는지 확인
    ↓
DB 쿼리? 외부 API? 내부 로직?
```

### "에러가 나요"

```
애플리케이션 로그 → 에러 레벨 필터 → 에러 메시지 확인
    ↓
로그에서 traceId 클릭 → Tempo로 이동
    ↓
분산 추적에서 어느 서비스에서 에러 났는지 확인
```

### "Pod가 자꾸 재시작해요"

```
애플리케이션 인프라 → 재시작 횟수 확인
    ↓
애플리케이션 로그 → 재시작 직전 시점 로그 확인
    ↓
OOM? (Killed) → 메모리 늘려야 함
에러? → 코드 수정 필요
```

### "메모리가 계속 올라가요"

```
애플리케이션 인프라 → 메모리 그래프 추이 확인
    ↓
계단식으로 올라감? → 메모리 누수 의심
    ↓
APM 개요 → 특정 API 호출 시 올라가는지 확인
```

---

## 팁

### 로그에서 트레이스로 바로 가기
로그 라인 클릭 → `traceId` 필드의 Tempo 링크 클릭

### 트레이스에서 로그로 바로 가기
트레이스 상세 → "View Logs" 버튼 클릭

### 시간 범위 맞추기
대시보드 우측 상단 시간 선택기에서 동일한 시간대로 맞추기
(알람 발생 시점 ±30분 정도)

---

## FAQ

**Q: 데이터가 안 보여요**
- 시간 범위 확인 (너무 좁으면 안 보임)
- 필터가 "All"인지 확인
- Pod가 Running 상태인지 확인

**Q: traceId 링크가 안 돼요**
- 로그에 traceId 필드가 있는지 확인
- 애플리케이션에 OpenTelemetry 설정이 되어 있어야 함

**Q: 메트릭이 No data예요**
- Prometheus가 애플리케이션을 스크랩하고 있는지 확인
- 애플리케이션 /actuator/prometheus 엔드포인트 확인
